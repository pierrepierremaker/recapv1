import os
from io import BytesIO
from typing import List

import streamlit as st
from dotenv import load_dotenv
from pydub import AudioSegment
from openai import OpenAI

# -----------------------
# 1. Chargement des variables d'environnement
# -----------------------
load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    client = None
else:
    client = OpenAI(api_key=api_key)

# -----------------------
# 2. Configuration de la page Streamlit
# -----------------------
st.set_page_config(
    page_title="Compte rendu de r√©union automatique",
    page_icon="üìù",
    layout="centered",
)

st.caption(f"üì¶ Taille max upload c√¥t√© Streamlit : {st.get_option('server.maxUploadSize')} Mo")

st.title("üìù G√©n√©rateur de compte rendu de r√©union")
st.write(
    "D√©pose un fichier audio de r√©union (MP3 / WAV) et l‚Äôoutil g√©n√©rera d‚Äôabord une transcription compl√®te, "
    "puis un compte rendu structur√© (dans les prochaines √©tapes)."
)

# -----------------------
# 3. Upload du fichier audio
# -----------------------
uploaded_file = st.file_uploader(
    "D√©pose ton fichier audio ici",
    type=["mp3", "wav", "m4a"],
    help="Formats support√©s : MP3, WAV, M4A",
)

status_placeholder = st.empty()

# -----------------------
# 4. Fonctions utilitaires
# -----------------------
def load_audio_to_pydub(file) -> AudioSegment:
    """Charge le fichier upload√© dans un objet AudioSegment (pydub)."""
    data = BytesIO(file.read())
    audio = AudioSegment.from_file(data)
    # On force en mono & 16 kHz pour plus de stabilit√©
    audio = audio.set_channels(1).set_frame_rate(16000)
    return audio


def split_audio(audio: AudioSegment, max_chunk_ms: int = 10 * 60 * 1000) -> List[AudioSegment]:
    """
    D√©coupe l'audio en morceaux (chunks) de dur√©e maximale max_chunk_ms (par d√©faut 10 minutes).
    Retourne une liste d'AudioSegment.
    """
    chunks = []
    total_length = len(audio)
    for start_ms in range(0, total_length, max_chunk_ms):
        end_ms = min(start_ms + max_chunk_ms, total_length)
        chunk = audio[start_ms:end_ms]
        chunks.append(chunk)
    return chunks


def estimate_whisper_cost(duration_minutes: float, price_per_minute_usd: float = 0.006) -> float:
    """
    Estime le co√ªt de transcription Whisper (whisper-1) en dollars.
    Par d√©faut : 0,006 $ / minute (√† ajuster si besoin).
    """
    return duration_minutes * price_per_minute_usd


def transcribe_chunk_with_whisper(chunk: AudioSegment, language: str = "fr") -> str:
    """
    Transcrit un chunk d'audio avec Whisper (whisper-1) et renvoie le texte.
    """
    if client is None:
        raise RuntimeError("Client OpenAI non initialis√© (cl√© API manquante).")

    # On exporte le chunk vers un buffer en m√©moire, en WAV (format tr√®s compatible)
    buffer = BytesIO()
    chunk.export(buffer, format="wav")
    buffer.seek(0)
    buffer.name = "chunk.wav"  # important pour que l'API reconnaisse le format

    transcription = client.audio.transcriptions.create(
        model="whisper-1",
        file=buffer,
        language=language,
    )
    return transcription.text


# -----------------------
# 5. Interface principale
# -----------------------
if uploaded_file is not None:
    st.success(f"‚úÖ Fichier charg√© : **{uploaded_file.name}**")
    st.write("Tu peux maintenant lancer la transcription audio ‚Üí texte.")

    # --------- 5.A ‚Äì Mode classique : Whisper + d√©coupage ---------
    st.markdown("### üéß Transcription classique (Whisper + d√©coupage)")

    # Slider pour r√©gler la dur√©e max d'un chunk (optionnel)
    chunk_length_minutes = st.slider(
        "Dur√©e maximale par morceau (chunk) pour la transcription",
        min_value=5,
        max_value=20,
        value=10,
        step=5,
        help="Cela permet de g√©rer de longues r√©unions sans d√©passer les limites de l'API.",
    )

    if st.button("Transcrire la r√©union (Whisper)"):
        if client is None:
            st.error("‚ùå Aucune cl√© API OpenAI d√©tect√©e. Configure OPENAI_API_KEY pour continuer.")
        else:
            try:
                # 1) Chargement de l'audio
                status_placeholder.info("‚è≥ Chargement de l'audio...")
                audio = load_audio_to_pydub(uploaded_file)

                duration_seconds = len(audio) / 1000
                duration_minutes = duration_seconds / 60
                st.write(f"üïí Dur√©e estim√©e de l'audio : **{duration_minutes:.1f} minutes**")

                # Estimation du co√ªt
                estimated_cost = estimate_whisper_cost(duration_minutes)
                st.write(f"üí∞ Co√ªt estim√© de la transcription (whisper-1) : ~**{estimated_cost:.4f} $**")

                # 2) D√©coupage en chunks
                status_placeholder.info("‚úÇÔ∏è D√©coupage de l'audio en morceaux...")
                max_chunk_ms = chunk_length_minutes * 60 * 1000
                chunks = split_audio(audio, max_chunk_ms=max_chunk_ms)
                st.write(f"üîπ Nombre de morceaux : **{len(chunks)}**")

                # 3) Transcription chunk par chunk
                status_placeholder.info("üó£Ô∏è Transcription en cours avec Whisper...")

                all_text_parts = []
                progress_bar = st.progress(0)
                total_chunks = len(chunks)

                for idx, chunk in enumerate(chunks, start=1):
                    status_placeholder.info(f"üó£Ô∏è Transcription du morceau {idx}/{total_chunks}...")
                    text = transcribe_chunk_with_whisper(chunk, language="fr")
                    all_text_parts.append(text)

                    progress_bar.progress(idx / total_chunks)

                full_transcript = "\n\n".join(all_text_parts)

                status_placeholder.success("‚úÖ Transcription termin√©e !")

                # 4) Affichage de la transcription
                st.subheader("üßæ Transcription compl√®te")
                st.write(
                    "Voici la transcription brute de la r√©union. "
                    "La prochaine √©tape consistera √† g√©n√©rer un compte rendu structur√© √† partir de ce texte."
                )
                st.text_area(
                    "Transcription",
                    value=full_transcript,
                    height=400,
                )

                # On garde dans la session pour utilisation future (r√©sum√©, CR, etc.)
                st.session_state["full_transcript"] = full_transcript

            except Exception as e:
                status_placeholder.error("‚ùå Erreur lors de la transcription.")
                st.error(str(e))

    # --------- 5.B ‚Äì Mode diarisation : gpt-4o-transcribe-diarize ---------
    st.markdown("### üîä Transcription avec identification des locuteurs")

    st.write(
        "Utilise ce mode si ton fichier fait **25 Mo ou moins**. "
        "Le mod√®le `gpt-4o-transcribe-diarize` ajoutera des labels de locuteurs (A, B, C...)."
    )

    if st.button("Transcrire avec diarisation (gpt-4o-transcribe-diarize)"):
        if client is None:
            st.error("‚ùå Aucune cl√© API OpenAI d√©tect√©e. Configure OPENAI_API_KEY pour continuer.")
        else:
            # 25 Mo = 25 * 1024 * 1024 octets
            max_bytes = 25 * 1024 * 1024
            if uploaded_file.size > max_bytes:
                st.error(
                    f"‚ùå Fichier trop volumineux pour la diarisation (taille : {uploaded_file.size/1024/1024:.1f} Mo). "
                    "La limite de l'API est 25 Mo. Utilise plut√¥t la transcription 'Whisper' avec d√©coupage."
                )
            else:
                try:
                    with st.spinner("üß† Transcription + diarisation en cours..."):
                        # On r√©cup√®re les bytes du fichier upload√©
                        audio_bytes = uploaded_file.getvalue()
                        buffer = BytesIO(audio_bytes)
                        # Donner un nom avec une extension reconnue
                        buffer.name = uploaded_file.name or "audio.wav"

                        diarized = client.audio.transcriptions.create(
                            model="gpt-4o-transcribe-diarize",
                            file=buffer,
                            response_format="diarized_json",
                            chunking_strategy="auto",
                        )

                        # diarized.segments contient les segments avec speaker / start / end / text
                        segments = diarized.segments

                        # On construit un texte lisible du type :
                        # Speaker A [0.0s‚Äì5.2s] : blabla
                        lines = []
                        for seg in segments:
                            speaker = seg.speaker
                            start = getattr(seg, "start", None)
                            end = getattr(seg, "end", None)
                            text = seg.text

                            if start is not None and end is not None:
                                lines.append(
                                    f"Speaker {speaker} [{start:.1f}s‚Äì{end:.1f}s] : {text}"
                                )
                            else:
                                lines.append(f"Speaker {speaker} : {text}")

                        labeled_transcript = "\n".join(lines)

                        st.success("‚úÖ Transcription diaris√©e termin√©e !")
                        st.subheader("üßæ Transcription avec locuteurs")
                        st.text_area(
                            "Texte diaris√© (qui parle, quand, quoi)",
                            value=labeled_transcript,
                            height=400,
                        )

                        # On garde √ßa dans la session pour le futur compte rendu
                        st.session_state["full_transcript"] = labeled_transcript

                except Exception as e:
                    st.error("‚ùå Erreur lors de la transcription avec diarisation.")
                    st.error(str(e))

else:
    st.info("‚§¥Ô∏è Commence par d√©poser un fichier audio pour continuer.")

# -----------------------
# 6. G√©n√©ration du compte rendu avec GPT-4o-mini
# -----------------------
st.markdown("---")
st.subheader("üß† G√©n√©rer un compte rendu de la r√©union")

if "full_transcript" not in st.session_state:
    st.info("‚û°Ô∏è Transcris d'abord une r√©union (avec ou sans diarisation) pour pouvoir g√©n√©rer un compte rendu.")
else:
    transcript_text = st.session_state["full_transcript"]

    st.write(
        "√Ä partir de la transcription ci-dessus, l‚Äôoutil va produire un compte rendu synth√©tique, "
        "structur√© par th√®mes et par intervenant."
    )

    # Optionnel : rappel de la transcription (extrait)
    with st.expander("Voir un extrait de la transcription utilis√©e"):
        st.text_area(
            "Transcription (extrait)",
            value=transcript_text[:2000] + ("..." if len(transcript_text) > 2000 else ""),
            height=200,
        )

    style = st.selectbox(
        "Style de compte rendu",
        ["Professionnel / neutre", "Bullet points synth√©tiques", "Version d√©taill√©e (proc√®s-verbal)"],
        index=0,
    )

    if st.button("‚ú® G√©n√©rer le compte rendu"):
        if client is None:
            st.error("‚ùå Aucune cl√© API OpenAI d√©tect√©e. Configure OPENAI_API_KEY pour continuer.")
        else:
            try:
                with st.spinner("üß† R√©daction du compte rendu en cours..."):
                    # On adapte un peu le ton selon le style choisi
                    if style == "Professionnel / neutre":
                        style_instruction = (
                            "R√©dige un compte rendu professionnel, neutre, bien structur√©, en fran√ßais, "
                            "avec des titres et sous-titres clairs."
                        )
                    elif style == "Bullet points synth√©tiques":
                        style_instruction = (
                            "Fais un r√©sum√© tr√®s synth√©tique sous forme de listes √† puces, en fran√ßais, "
                            "en mettant surtout en avant les id√©es cl√©s et les chiffres importants."
                        )
                    else:  # Version d√©taill√©e (proc√®s-verbal)
                        style_instruction = (
                            "R√©dige un compte rendu d√©taill√©, proche d'un proc√®s-verbal, en fran√ßais, "
                            "en respectant fid√®lement le contenu sans inventer de faits."
                        )

                    system_msg = (
                        "Tu es un assistant charg√© de r√©diger des comptes rendus de r√©unions √† partir de transcriptions. "
                        "Tu dois √™tre clair, structur√©, fid√®le au contenu, et ne pas inventer de d√©cisions ou de chiffres. "
                        "Lorsque la transcription contient des √©tiquettes de locuteur comme 'Speaker A' ou 'Speaker B', "
                        "explique dans le compte rendu qui semble √™tre qui (ex : intervieweur, invit√©, expert...), "
                        "sans inventer d'identit√© r√©elle."
                    )

                    user_prompt = (
                        f"{style_instruction}\n\n"
                        "Voici la transcription de l'√©change (avec √©ventuellement des labels de locuteurs) :\n\n"
                        f"{transcript_text}\n\n"
                        "Produit maintenant le compte rendu demand√©."
                    )

                    resp = client.responses.create(
                        model="gpt-4o-mini",
                        input=[
                            {"role": "system", "content": system_msg},
                            {"role": "user", "content": user_prompt},
                        ],
                    )

                    cr_texte = resp.output[0].content[0].text

                st.subheader("üìÑ Compte rendu g√©n√©r√©")
                st.write(cr_texte)

                # Option : on stocke le CR dans la session pour r√©utilisation ult√©rieure (export, etc.)
                st.session_state["meeting_summary"] = cr_texte

            except Exception as e:
                st.error("‚ùå Erreur lors de la g√©n√©ration du compte rendu.")
                st.error(str(e))
